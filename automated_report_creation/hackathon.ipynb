{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7d756b-9b2d-4c3b-a3c4-b657b0661a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################\n",
    "# hackathon Boavizta at Orange Gardens - May 24th, 2024 #\n",
    "#########################################################\n",
    "\n",
    "\"\"\"\n",
    "______   _______  _______          _________ _______ _________ _______               _______  _______  _        _______ _________          _______  _       \n",
    "(  ___ \\ (  ___  )(  ___  )|\\     /|\\__   __// ___   )\\__   __/(  ___  )    |\\     /|(  ___  )(  ____ \\| \\    /\\(  ___  )\\__   __/|\\     /|(  ___  )( (    /|\n",
    "| (   ) )| (   ) || (   ) || )   ( |   ) (   \\/   )  |   ) (   | (   ) |    | )   ( || (   ) || (    \\/|  \\  / /| (   ) |   ) (   | )   ( || (   ) ||  \\  ( |\n",
    "| (__/ / | |   | || (___) || |   | |   | |       /   )   | |   | (___) |    | (___) || (___) || |      |  (_/ / | (___) |   | |   | (___) || |   | ||   \\ | |\n",
    "|  __ (  | |   | ||  ___  |( (   ) )   | |      /   /    | |   |  ___  |    |  ___  ||  ___  || |      |   _ (  |  ___  |   | |   |  ___  || |   | || (\\ \\) |\n",
    "| (  \\ \\ | |   | || (   ) | \\ \\_/ /    | |     /   /     | |   | (   ) |    | (   ) || (   ) || |      |  ( \\ \\ | (   ) |   | |   | (   ) || |   | || | \\   |\n",
    "| )___) )| (___) || )   ( |  \\   /  ___) (___ /   (_/\\   | |   | )   ( |    | )   ( || )   ( || (____/\\|  /  \\ \\| )   ( |   | |   | )   ( || (___) || )  \\  |\n",
    "|/ \\___/ (_______)|/     \\|   \\_/   \\_______/(_______/   )_(   |/     \\|    |/     \\||/     \\|(_______/|_/    \\/|/     \\|   )_(   |/     \\|(_______)|/    )_)\n",
    "                                                                                                                                                             \n",
    " _______ _________     _______  _______  _______  _        _______  _______      _______  _______  _______  ______   _______  _        _______               \n",
    "(  ___  )\\__   __/    (  ___  )(  ____ )(  ___  )( (    /|(  ____ \\(  ____ \\    (  ____ \\(  ___  )(  ____ )(  __  \\ (  ____ \\( (    /|(  ____ \\              \n",
    "| (   ) |   ) (       | (   ) || (    )|| (   ) ||  \\  ( || (    \\/| (    \\/    | (    \\/| (   ) || (    )|| (  \\  )| (    \\/|  \\  ( || (    \\/              \n",
    "| (___) |   | |       | |   | || (____)|| (___) ||   \\ | || |      | (__        | |      | (___) || (____)|| |   ) || (__    |   \\ | || (_____               \n",
    "|  ___  |   | |       | |   | ||     __)|  ___  || (\\ \\) || | ____ |  __)       | | ____ |  ___  ||     __)| |   | ||  __)   | (\\ \\) |(_____  )              \n",
    "| (   ) |   | |       | |   | || (\\ (   | (   ) || | \\   || | \\_  )| (          | | \\_  )| (   ) || (\\ (   | |   ) || (      | | \\   |      ) |              \n",
    "| )   ( |   | |       | (___) || ) \\ \\__| )   ( || )  \\  || (___) || (____/\\    | (___) || )   ( || ) \\ \\__| (__/  )| (____/\\| )  \\  |/\\____) |              \n",
    "|/     \\|   )_(       (_______)|/   \\__/|/     \\||/    )_)(_______)(_______/    (_______)|/     \\||/   \\__/(______/ (_______/|/    )_)\\_______)              \n",
    "                                                                                                                                                             \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a519a43-329a-4b2a-a615-d8ee0b2fea3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies\n",
    "from PIL import Image\n",
    "import os\n",
    "import uuid\n",
    "import json\n",
    "from joblib import load\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import pathlib\n",
    "import shutil\n",
    "import math\n",
    "import datetime\n",
    "from typing import List, Tuple\n",
    "import sys\n",
    "from codecarbon import EmissionsTracker\n",
    "from api.api import Algorithm, Dataset, Hardware, Measure, Report_Header, Report_Task, Report_System, Report_Software, Report_Region, Report_Hash, Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d511d90-05a0-4cb7-93c1-be1a0875bc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image settings\n",
    "import tensorflow.keras.backend as K\n",
    "K.set_image_data_format('channels_last') # can be channels_first or channels_last. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59c9ac3-faf7-4d19-b15d-0c405d534753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "TARGET_POPULATION_PER_CLASS = 5000\n",
    "BATCH_SIZES = [ 16, 32, 64 ]\n",
    "EPOCHS = 32\n",
    "ACTIVATION = 'softmax'\n",
    "CLASSIFIERS = [ 'baseline', 'resnet_50', 'inception_v3' ]\n",
    "OPTIMIZERS = [ 'adam', 'adamw', 'nadam' ]\n",
    "JOBLIB_FILE_EXTENSION = 'joblib'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a7922b-92be-4d3d-9bfa-153ccfdc6dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "\n",
    "\"\"\"ATTENTION PLEASE! Feel free to modify these values in order to avoid too long tasks. \n",
    "Please respect the values' ranges or enums.\n",
    "\"\"\"\n",
    "image_size = 100            # default - possible values from 96 to 192\n",
    "batch_size = 16             # default - possible values in BATCH_SIZES\n",
    "percent = 0.2               # default - possible values from 0.0 to 1.0\n",
    "algorithm = 'baseline'      # default - possible values in CLASSIFIERS\n",
    "early_stopping = True       # default - possible values True / False\n",
    "optimizer = 'adam'          # default - possible values in OPTIMIZERS\n",
    "learning_rate = 0.001       # default\n",
    "report_folder = os.sep.join(['.', 'out'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225d99e3-a24f-4ed9-928e-6f2bc37b0358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths\n",
    "report_filepath = os.sep.join([ report_folder, 'report-img_{}-batch_{}-pc_{}-alg_{}-es_{}-opt_{}-lr_{}.json'.format(str(image_size), str(batch_size), str(percent), str(algorithm), str(early_stopping), optimizer, str(learning_rate))])\n",
    "cc_filename = 'emissions_codecarbon-img_{}-batch_{}-pc_{}-alg_{}-es_{}-opt_{}-lr_{}.csv'.format(str(image_size), str(batch_size), str(percent), str(algorithm), str(early_stopping), optimizer, str(learning_rate))\n",
    "os.makedirs(report_folder, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e074add5-29eb-4a9a-a26f-d222c0a62a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# report instantiation\n",
    "\n",
    "\"\"\"ATTENTION! The main purpose of the Hackathon's discussions and achievements is here: fill automatically as many fields as possible \n",
    "in the report object below, either at runtime and/or thanks to code introspection techniques.\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"The main object does not instantiate automatically the sub-object, because the JSON schema parser is currently sketchy. \n",
    "Not a big issue right now.\n",
    "\"\"\"\n",
    "report = Report()\n",
    "\n",
    "\"\"\"The header part has a set of semi-static parameters to identify the publisher. \n",
    "Could be done quite trivially from a config file or environment variables.\n",
    "\"\"\"\n",
    "report.header = Report_Header()\n",
    "\n",
    "\"\"\"Here the challenges begin! First, not all ML tasks manipulate datasets (think about an inference situation).\n",
    "We use the datasets property typically if the tasks consists in a fit, a fine-tuning, a re-train, and the like.\n",
    "Please notice there can be more than 1 dataset involved in a single task.\n",
    "That said, it seems natural to retrieve the 'physionomy' of the dataset(s) at runtime.\n",
    "...Which would mean a wrapper of the ML library (say, Keras, for example), capable to manage a kind of 'binding' \n",
    "to the energy monitoring object (say, CodeCarbon, for example). Or reciprocally.\n",
    "...Alternatively, we could think about a system of decorators on the corresponding variables (to mean explicitly: \n",
    "'this variable contains the dataset from which we aim at retrieving properties').\n",
    "\"\"\"\n",
    "report.datasets = [ Dataset() ]\n",
    "\n",
    "\"\"\"The measures property is where measures are stored. Once again, it is considered as a collection, \n",
    "in case the developer put concurrent energy monitoring solutions in the code (say, CodeCarbon vs Carbon AI).\n",
    "No technical challenge since it is basically a copy-paste of the measures performed by the monitoring solution(s) in a dedicated object.\n",
    "\"\"\"\n",
    "report.measures = [ Measure() ]\n",
    "\n",
    "\"\"\"Defining automatically the ML task (or even general IT task) being performed is a tricky part.\n",
    "For most common ML libraries, some typical tasks may be identified.\n",
    "...In particular, if the task, per se, is atomic. A training would be recognized easily by a method named 'fit(...)'.\n",
    "In our case below, the ML task is the training of an image classifier. Line 'o = model.fit(...)' with function play(...) below.\n",
    "How to handle properly this simple case? At runtime? Through offline introspection?\n",
    "What about non-atomic tasks? Can some heuristic search help to make a smart guess to determine what the code is all about?\n",
    "\"\"\"\n",
    "report.task = Report_Task()\n",
    "\n",
    "\"\"\"System information is clearly an easy data retrieval (platform.system() and that kind of things).\n",
    "\"\"\"\n",
    "report.system = Report_System()\n",
    "\n",
    "\"\"\"Software environment, likewise, is an easy data retrival (sys.version_info and that kind of things).\n",
    "\"\"\"\n",
    "report.software = Report_Software()\n",
    "\n",
    "\"\"\"Access to regional information is a native functionality of most energy monitoring libraries. \n",
    "There is accordingly no big challenge other than making a copy-paste from the library (say, CodeCarbon) to this property.\n",
    "\"\"\"\n",
    "report.region = Report_Region()\n",
    "\n",
    "\"\"\"The hash is computed at the end of the process, when the report is completed. \n",
    "It embarks different purposes such as integrity and authentication of the publisher (if desired).\n",
    "The hash may be computed on-the-fly by the process which sends the report to the open data repository.\n",
    "\"\"\"\n",
    "report.hash = Report_Hash()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7334de3e-ff48-470a-9450-bc0a6136f855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup energy monitor instance\n",
    "print('starting energy tracker')\n",
    "cc_tracker = EmissionsTracker(project_name='Hackathon Boavizta', measure_power_secs=10, save_to_file=True, output_dir=report_folder, output_file=cc_filename, log_level='error')\n",
    "cc_tracker.start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4809ad4-2653-46f6-a276-caadce158383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download and explore dataset\n",
    "dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
    "data_dir = pathlib.Path(tf.keras.utils.get_file('flower_photos.tar', origin=dataset_url, extract=True)).with_suffix('')\n",
    "data_dir_s = str(data_dir)\n",
    "emissions_start = cc_tracker.flush()\n",
    "print('download, emissions start '+str(emissions_start))\n",
    "shutil.rmtree(data_dir_s, ignore_errors=True)\n",
    "data_dir = pathlib.Path(tf.keras.utils.get_file('flower_photos.tar', origin=dataset_url, extract=True)).with_suffix('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1eed555-5169-4ad8-8d2f-259777fb8e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create folder for unused data\n",
    "print('directories setup')\n",
    "path_elements = data_dir_s.split(os.sep)\n",
    "path_elements[-1] = '~'+path_elements[-1]\n",
    "unused_dir_s = os.sep.join(path_elements)\n",
    "shutil.rmtree(unused_dir_s, ignore_errors=True)\n",
    "os.makedirs(unused_dir_s, exist_ok=True)\n",
    "subfolders = [ f.name for f in os.scandir(data_dir_s) if f.is_dir() ]\n",
    "for subfolder in subfolders:\n",
    "    subfolder_path_elements = path_elements + [ subfolder ]\n",
    "    subfolder_path = os.sep.join(subfolder_path_elements)\n",
    "    os.makedirs(subfolder_path, exist_ok=True)\n",
    "emissions_stop = cc_tracker.flush()\n",
    "print('download, emissions stop '+str(emissions_stop))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a5e2b6-eeba-4484-b97a-319f4798962c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# images centered-square cropping\n",
    "print('crop dataset')\n",
    "for subfolder in subfolders:\n",
    "    subfolder_content = list(os.scandir(os.sep.join([ data_dir_s, subfolder ])))\n",
    "    for f in subfolder_content:\n",
    "        img = Image.open(f.path)\n",
    "        # keep image vertical despite possible undue transformation at loading time\n",
    "        if img.size[0] > img.size[1]:\n",
    "            img = img.transpose(Image.Transpose.ROTATE_270)\n",
    "        half_square_side = int(min(img.size[0], img.size[1])/2)-1\n",
    "        img = img.crop((int(img.size[0]/2)-half_square_side, int(img.size[1]/2)-half_square_side, int(img.size[0]/2)+half_square_side, int(img.size[1]/2)+half_square_side))\n",
    "        img.save(fp=f.path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3fa6dd-0e76-4d7c-a57a-3bbadcb3e0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# frozen random numbers\n",
    "print('load permanent random filenames')\n",
    "initial_renames = load(filename=os.sep.join([ '.', '.'.join([ 'initial_renames', JOBLIB_FILE_EXTENSION ])]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbd975c-e203-4eb5-9ea2-462558584ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename original files\n",
    "index = 0\n",
    "for subfolder in subfolders:\n",
    "    data_dir_subfolder = os.sep.join([ data_dir_s, subfolder ])\n",
    "    for f in list(os.scandir(data_dir_subfolder)):\n",
    "        shutil.move(f.path, os.sep.join([ data_dir_subfolder, '.'.join([ initial_renames[index], 'jpg' ]) ]))\n",
    "        index += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa94938-5dd9-4ef7-b43b-4f0657b5a2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# frozen image transformations\n",
    "print('load permanent random transformations')\n",
    "transformations = load(filename=os.sep.join([ '.', '.'.join([ 'transformations', JOBLIB_FILE_EXTENSION ])]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07709f6-0c40-48ae-9bcc-f9f99a0c7de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra images generation to get balanced classes\n",
    "print('balance classes with extra images')\n",
    "index_bis = 0\n",
    "for subfolder in subfolders:\n",
    "    subfolder_index = 0\n",
    "    subfolder_content = list(os.scandir(os.sep.join([ data_dir_s, subfolder ])))\n",
    "    class_population = len(subfolder_content)\n",
    "    if class_population >= TARGET_POPULATION_PER_CLASS:\n",
    "        continue\n",
    "    for i in range(class_population, TARGET_POPULATION_PER_CLASS):\n",
    "        img = Image.open(subfolder_content[subfolder_index].path)    \n",
    "        # flip horizontally and vertically on a random basis\n",
    "        if transformations[index_bis]['flip_lr']:\n",
    "            img = img.transpose(Image.Transpose.FLIP_LEFT_RIGHT)\n",
    "        if transformations[index_bis]['flip_tb']:\n",
    "            img = img.transpose(Image.Transpose.FLIP_TOP_BOTTOM)\n",
    "        half_square_side = int(transformations[index_bis]['zoom_factor'] * min(img.size[0], img.size[1])/3)\n",
    "        img = img.rotate(angle=transformations[index_bis]['angle']*transformations[index_bis]['angle_sign'])\n",
    "        img = img.crop((int(img.size[0]/2)-half_square_side, int(img.size[1]/2)-half_square_side, int(img.size[0]/2)+half_square_side, int(img.size[1]/2)+half_square_side))\n",
    "        img.save(fp=os.sep.join([ unused_dir_s, subfolder, '.'.join([ initial_renames[index], 'jpg' ]) ]))\n",
    "        index += 1\n",
    "        index_bis +=1\n",
    "        subfolder_index += 1\n",
    "        if subfolder_index == len(subfolder_content):\n",
    "            subfolder_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb9a4a8-0d22-4cee-b6b7-54d0d616510c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# move per class a ratio of random files to reduce the number of items processed\n",
    "def split_files_per_class(percent_used:float=1.0):\n",
    "    for subfolder in subfolders:\n",
    "        # first, reset the directories\n",
    "        data_dir_subfolder = os.sep.join([ data_dir_s, subfolder ])\n",
    "        unused_dir_subfolder = os.sep.join([ unused_dir_s, subfolder ])\n",
    "        for f in os.scandir(unused_dir_subfolder):\n",
    "            shutil.move(f.path, os.sep.join([ data_dir_subfolder, f.name ]))\n",
    "            \n",
    "        # proceed with moving percentage\n",
    "        if percent_used > 0.999:\n",
    "            continue\n",
    "        class_image_count = len(list(data_dir.glob('{}{}*.jpg'.format(subfolder, os.sep))))\n",
    "        num_to_move = int(math.floor((1.0-percent_used)*class_image_count))\n",
    "        for i in range(0, num_to_move):\n",
    "            random_file=os.listdir(data_dir_subfolder)[0]\n",
    "            shutil.move(os.sep.join([ data_dir_subfolder, random_file ]),\n",
    "                        os.sep.join([ unused_dir_subfolder, random_file ]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3bece9-7cd3-459b-8e88-eaca6644dd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset after initial images generation\n",
    "print('move extra images to active space')\n",
    "split_files_per_class()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c86edff-deb6-4b7d-8107-ea2cf0175d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# images count and folder info\n",
    "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "print(str(image_count))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424d4158-5b47-44a8-b2c4-0c4c2b86aeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# naive baseline classifier\n",
    "def baseline(img_size:int, classes:int, activation:str='softmax') -> Model:\n",
    "  return Sequential([\n",
    "      Input((img_size, img_size, 3)),\n",
    "      layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "      layers.MaxPooling2D(),\n",
    "      layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "      layers.MaxPooling2D(),\n",
    "      layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "      layers.MaxPooling2D(),\n",
    "      layers.Dropout(0.2),\n",
    "      layers.Flatten(),\n",
    "      layers.Dense(128, activation='relu'),\n",
    "      layers.Dense(classes, activation=activation, name='outputs')\n",
    "  ])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3ca08c-b7bf-4dac-b8a0-d3780050d2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inception v3 model\n",
    "def inception_v3(img_size:int, classes:int, activation:str='softmax') -> Model:\n",
    "    model = tf.keras.applications.InceptionV3(\n",
    "        include_top=True,\n",
    "        input_tensor=None,\n",
    "        weights=None,\n",
    "        input_shape=(img_size, img_size, 3),\n",
    "        pooling=None,\n",
    "        classes=classes,\n",
    "        classifier_activation=activation,\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32488367-52d5-467b-a59e-fa1e907b41e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet50 identity block\n",
    "def identity_block(X: tf.Tensor, level: int, block: int, filters: List[int]) -> tf.Tensor:\n",
    "    # layers will be called conv{level}_iden{block}_{convlayer_number_within_block}'\n",
    "    conv_name = f'conv{level}_{block}' + '_{layer}_{type}'\n",
    "    # unpack number of filters to be used for each conv layer\n",
    "    f1, f2, f3 = filters\n",
    "    # the shortcut branch of the identity block\n",
    "    # takes the value of the block input\n",
    "    X_shortcut = X\n",
    "    # first convolutional layer (plus batch norm & relu activation, of course)\n",
    "    X = Conv2D(filters=f1, kernel_size=(1, 1), strides=(1, 1),\n",
    "               padding='valid', name=conv_name.format(layer=1, type='conv'),\n",
    "               kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=conv_name.format(layer=1, type='bn'))(X)\n",
    "    X = Activation('relu', name=conv_name.format(layer=1, type='relu'))(X)\n",
    "    # second convolutional layer\n",
    "    X = Conv2D(filters=f2, kernel_size=(3, 3), strides=(1, 1),\n",
    "               padding='same', name=conv_name.format(layer=2, type='conv'),\n",
    "               kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=conv_name.format(layer=2, type='bn'))(X)\n",
    "    X = Activation('relu')(X)\n",
    "    # third convolutional layer\n",
    "    X = Conv2D(filters=f3, kernel_size=(1, 1), strides=(1, 1),\n",
    "               padding='valid', name=conv_name.format(layer=3, type='conv'),\n",
    "               kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=conv_name.format(layer=3, type='bn'))(X)\n",
    "    # add shortcut branch to main path\n",
    "    X = Add()([X, X_shortcut])\n",
    "    # relu activation at the end of the block\n",
    "    X = Activation('relu', name=conv_name.format(layer=3, type='relu'))(X)\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a30789f-8ed4-4c7e-988c-414838d66c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet50 convolutional block\n",
    "def convolutional_block(X: tf.Tensor, level: int, block: int, filters: List[int], s: Tuple[int,int,int]=(2, 2)) -> tf.Tensor:\n",
    "     # layers will be called conv{level}_{block}_{convlayer_number_within_block}'\n",
    "    conv_name = f'conv{level}_{block}' + '_{layer}_{type}'\n",
    "    # unpack number of filters to be used for each conv layer\n",
    "    f1, f2, f3 = filters\n",
    "    # the shortcut branch of the convolutional block\n",
    "    X_shortcut = X\n",
    "    # first convolutional layer\n",
    "    X = Conv2D(filters=f1, kernel_size=(1, 1), strides=s, padding='valid',\n",
    "               name=conv_name.format(layer=1, type='conv'),\n",
    "               kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=conv_name.format(layer=1, type='bn'))(X)\n",
    "    X = Activation('relu', name=conv_name.format(layer=1, type='relu'))(X)\n",
    "    # second convolutional layer\n",
    "    X = Conv2D(filters=f2, kernel_size=(3, 3), strides=(1, 1), padding='same',\n",
    "               name=conv_name.format(layer=2, type='conv'),\n",
    "               kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=conv_name.format(layer=2, type='bn'))(X)\n",
    "    X = Activation('relu', name=conv_name.format(layer=2, type='relu'))(X)\n",
    "    # third convolutional layer\n",
    "    X = Conv2D(filters=f3, kernel_size=(1, 1), strides=(1, 1), padding='valid',\n",
    "               name=conv_name.format(layer=3, type='conv'),\n",
    "               kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=conv_name.format(layer=3, type='bn'))(X)\n",
    "    # shortcut path\n",
    "    X_shortcut = Conv2D(filters=f3, kernel_size=(1, 1), strides=s, padding='valid',\n",
    "                        name=conv_name.format(layer='short', type='conv'),\n",
    "                        kernel_initializer=glorot_uniform(seed=0))(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis=3, name=conv_name.format(layer='short', type='bn'))(X_shortcut)\n",
    "    # add shortcut branch to main path\n",
    "    X = Add()([X, X_shortcut])\n",
    "    # nonlinearity\n",
    "    X = Activation('relu', name=conv_name.format(layer=3, type='relu'))(X)\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e33319e-93fb-4eaa-a7e6-54d61dc9213b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet50 model\n",
    "def resnet_50(img_size:int, classes:int, activation:str='softmax') -> Model:\n",
    "    input_size = (img_size, img_size, 3)\n",
    "    # tensor placeholder for the model's input\n",
    "    X_input = Input(input_size)\n",
    "    ### Level 1 ###\n",
    "    # padding\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "    # convolutional layer, followed by batch normalization and relu activation\n",
    "    X = Conv2D(filters=64, kernel_size=(7, 7), strides=(2, 2),\n",
    "               name='conv1_1_1_conv',\n",
    "               kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name='conv1_1_1_nb')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    ### Level 2 ###\n",
    "    # max pooling layer to halve the size coming from the previous layer\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "    # 1x convolutional block\n",
    "    X = convolutional_block(X, level=2, block=1, filters=[64, 64, 256], s=(1, 1))\n",
    "    # 2x identity blocks\n",
    "    X = identity_block(X, level=2, block=2, filters=[64, 64, 256])\n",
    "    X = identity_block(X, level=2, block=3, filters=[64, 64, 256])\n",
    "    ### Level 3 ###\n",
    "    # 1x convolutional block\n",
    "    X = convolutional_block(X, level=3, block=1, filters=[128, 128, 512], s=(2, 2))\n",
    "    # 3x identity blocks\n",
    "    X = identity_block(X, level=3, block=2, filters=[128, 128, 512])\n",
    "    X = identity_block(X, level=3, block=3, filters=[128, 128, 512])\n",
    "    X = identity_block(X, level=3, block=4, filters=[128, 128, 512])\n",
    "    ### Level 4 ###\n",
    "    # 1x convolutional block\n",
    "    X = convolutional_block(X, level=4, block=1, filters=[256, 256, 1024], s=(2, 2))\n",
    "    # 5x identity blocks\n",
    "    X = identity_block(X, level=4, block=2, filters=[256, 256, 1024])\n",
    "    X = identity_block(X, level=4, block=3, filters=[256, 256, 1024])\n",
    "    X = identity_block(X, level=4, block=4, filters=[256, 256, 1024])\n",
    "    X = identity_block(X, level=4, block=5, filters=[256, 256, 1024])\n",
    "    X = identity_block(X, level=4, block=6, filters=[256, 256, 1024])\n",
    "    ### Level 5 ###\n",
    "    # 1x convolutional block\n",
    "    X = convolutional_block(X, level=5, block=1, filters=[512, 512, 2048], s=(2, 2))\n",
    "    # 2x identity blocks\n",
    "    X = identity_block(X, level=5, block=2, filters=[512, 512, 2048])\n",
    "    X = identity_block(X, level=5, block=3, filters=[512, 512, 2048])\n",
    "    # Pooling layers\n",
    "    X = AveragePooling2D(pool_size=(2, 2), name='avg_pool')(X)\n",
    "    # Output layer\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation=activation, name='fc_' + str(classes),\n",
    "              kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    # Create model\n",
    "    model = Model(inputs=X_input, outputs=X, name='ResNet50')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4ec608-da06-4140-87a4-c5f600fbd9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unitary model training and validation\n",
    "def play(cc_tracker:EmissionsTracker=None, model_name:str='baseline', batch_size:int=32, img_size:int=80, epochs:int=256, percent_used:float=1.0, activation:str='softmax', es:bool=True, optimizer:str='adam', learning_rate:float=0.001, report:dict=None):\n",
    "    session_id = str(uuid.uuid4())\n",
    "\n",
    "    try:\n",
    "        print('flush CodeCarbon tracker')\n",
    "        emissions_start = cc_tracker.flush() if cc_tracker is not None else 1.0\n",
    "\n",
    "        # tailor dataset according to percent desired\n",
    "        print('split files')\n",
    "        split_files_per_class(percent_used)\n",
    "\n",
    "        # train\n",
    "        print('train dataset setup')\n",
    "        train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        data_dir,\n",
    "        validation_split=0.2,\n",
    "        subset='training',\n",
    "        seed=123,\n",
    "        image_size=(img_size, img_size),\n",
    "        batch_size=batch_size)\n",
    "\n",
    "        # validation\n",
    "        print('validation dataset setup')\n",
    "        val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        data_dir,\n",
    "        validation_split=0.2,\n",
    "        subset='validation',\n",
    "        seed=123,\n",
    "        image_size=(img_size, img_size),\n",
    "        batch_size=batch_size)\n",
    "        \n",
    "        # classes\n",
    "        class_names = train_ds.class_names\n",
    "        num_classes = len(class_names)\n",
    "        print('number of classes: '+str(num_classes))\n",
    "\n",
    "        # normalize\n",
    "        print('normalization')\n",
    "        normalization_layer = layers.experimental.preprocessing.Rescaling(1./255)\n",
    "        norm_train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "        norm_val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "        image_batch, labels_batch = next(iter(norm_train_ds))\n",
    "\n",
    "        # setup autotune\n",
    "        print('autotune')\n",
    "        AUTOTUNE = tf.data.AUTOTUNE\n",
    "        norm_train_ds = norm_train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "        norm_val_ds = norm_val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "        # model\n",
    "        print('model build')\n",
    "        if model_name not in CLASSIFIERS:\n",
    "            print('unknown model')\n",
    "            return None\n",
    "        model_func_call = '{}(img_size={}, classes={}, activation=\"{}\")'.format(model_name, str(img_size), str(num_classes), activation)\n",
    "        print('model function call is '+model_func_call)\n",
    "        op = None\n",
    "        if optimizer not in OPTIMIZERS:\n",
    "            print('unknown optimzer')\n",
    "            return None\n",
    "        beta_1 = max(0.5, 1.0-100*learning_rate)\n",
    "        beta_2 = max(0.95, 1.0-learning_rate)\n",
    "        if optimizer == 'adam':\n",
    "            op = tf.keras.optimizers.Adam(learning_rate=learning_rate, beta_1=beta_1, beta_2=beta_2)\n",
    "        elif optimizer == 'adamw':\n",
    "            op = tf.keras.optimizers.AdamW(learning_rate=learning_rate, beta_1=beta_1, beta_2=beta_2)\n",
    "        elif optimizer == 'nadam':\n",
    "            op = tf.keras.optimizers.Nadam(learning_rate=learning_rate, beta_1=beta_1, beta_2=beta_2)\n",
    "        model = eval(model_func_call)\n",
    "        model.compile(optimizer=op,\n",
    "                        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                        metrics=['accuracy'])\n",
    "        early = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=int(max(2, math.floor(epochs*0.1))), verbose=1, mode='auto')\n",
    "\n",
    "        \"\"\"The main task is HERE!\n",
    "        \"\"\"\n",
    "        o = model.fit(norm_train_ds, validation_data=norm_val_ds, epochs=epochs, callbacks=[early]) if es else model.fit(norm_train_ds, validation_data=norm_val_ds, epochs=epochs)\n",
    "        \n",
    "        # visualize new training results\n",
    "        acc = o.history['accuracy']\n",
    "        val_acc = o.history['val_accuracy']\n",
    "        loss = o.history['loss']\n",
    "        val_loss = o.history['val_loss']\n",
    "        stopped_epoch = epochs if early.stopped_epoch <= 0 else early.stopped_epoch\n",
    "\n",
    "    except Exception as err:\n",
    "        \"\"\"TODO\n",
    "        You probably want to do something with the report when things went wrong...\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    \"\"\"TODO\n",
    "    A certain number of properties of the report should be populated here.\n",
    "    Pay attention to the fact that the code must stay generic. It is NOT aware of the roles played by each variable.\n",
    "    \"\"\"\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5e758a-1e30-4b4b-a8b1-d94a74d19c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main task\n",
    "print('starting play model {} size {} epochs {} percent {} activation {} early stopping {}'.format(algorithm, str(image_size), str(EPOCHS), str(percent), ACTIVATION, str(early_stopping)))\n",
    "try:\n",
    "\n",
    "    play(\n",
    "        cc_tracker=cc_tracker, \n",
    "        model_name=algorithm, \n",
    "        batch_size=batch_size, \n",
    "        img_size=image_size, \n",
    "        epochs=EPOCHS, \n",
    "        percent_used=percent, \n",
    "        activation=ACTIVATION, \n",
    "        es=early_stopping,\n",
    "        optimizer=optimizer,\n",
    "        learning_rate=learning_rate,\n",
    "        report=report)\n",
    "\n",
    "except Exception as err:\n",
    "    print('exception raised: '+str(err))\n",
    "\n",
    "print('ending play model')\n",
    "split_files_per_class() # reset directories' content\n",
    "cc_tracker.stop() \n",
    "\n",
    "\"\"\"TODO\n",
    "Persist the report somewhere, for further propagation to the open data repository.\n",
    "ENJOY!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3380c5f1-20ca-40b9-9faf-8e913f8ed07f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
