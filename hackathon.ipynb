{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7d756b-9b2d-4c3b-a3c4-b657b0661a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hackathon Boavizta at Orange Gardens - May 24th, 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a519a43-329a-4b2a-a615-d8ee0b2fea3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies\n",
    "from PIL import Image\n",
    "import os\n",
    "import uuid\n",
    "import json\n",
    "from joblib import load\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import pathlib\n",
    "import shutil\n",
    "import math\n",
    "import datetime\n",
    "from typing import List, Tuple\n",
    "import sys\n",
    "from codecarbon import EmissionsTracker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d511d90-05a0-4cb7-93c1-be1a0875bc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image settings\n",
    "import tensorflow.keras.backend as K\n",
    "K.set_image_data_format('channels_last') # can be channels_first or channels_last. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59c9ac3-faf7-4d19-b15d-0c405d534753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "TARGET_POPULATION_PER_CLASS = 5000\n",
    "BATCH_SIZES = [ 16, 32, 64 ]\n",
    "EPOCHS = 128\n",
    "ACTIVATION = 'softmax'\n",
    "CLASSIFIERS = [ 'baseline', 'resnet_50', 'inception_v3' ]\n",
    "OPTIMIZERS = [ 'adam', 'adamw', 'nadam' ]\n",
    "JOBLIB_FILE_EXTENSION = 'joblib'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a7922b-92be-4d3d-9bfa-153ccfdc6dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "image_size = 100            # default - possible values from 96 to 192\n",
    "batch_size = 16             # default - possible values in BATCH_SIZES\n",
    "percent = 0.2               # default - possible values from 0.0 to 1.0\n",
    "algorithm = 'baseline'      # default - possible values in CLASSIFIERS\n",
    "early_stopping = True       # default - possible values True / False\n",
    "optimizer = 'adam'          # default - possible values in OPTIMIZERS\n",
    "learning_rate = 0.001       # default\n",
    "report_folder = os.sep.join(['.', 'out'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225d99e3-a24f-4ed9-928e-6f2bc37b0358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths\n",
    "report_filepath = os.sep.join([ report_folder, 'report-img_{}-batch_{}-pc_{}-alg_{}-es_{}-opt_{}-lr_{}.json'.format(str(image_size), str(batch_size), str(percent), str(algorithm), str(early_stopping), optimizer, str(learning_rate))])\n",
    "cc_filename = 'emissions_codecarbon-img_{}-batch_{}-pc_{}-alg_{}-es_{}-opt_{}-lr_{}.csv'.format(str(image_size), str(batch_size), str(percent), str(algorithm), str(early_stopping), optimizer, str(learning_rate))\n",
    "os.makedirs(report_folder, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e074add5-29eb-4a9a-a26f-d222c0a62a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# report\n",
    "report = {\n",
    "    'download': {\n",
    "        'energy': {\n",
    "            'codecarbon': None\n",
    "        }\n",
    "    },\n",
    "    'train': {}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7334de3e-ff48-470a-9450-bc0a6136f855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup energy monitor instance\n",
    "print('starting energy tracker')\n",
    "cc_tracker = EmissionsTracker(project_name='Hackathon Boavizta', measure_power_secs=10, save_to_file=True, output_dir=report_folder, output_file=cc_filename, log_level='error')\n",
    "cc_tracker.start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4809ad4-2653-46f6-a276-caadce158383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download and explore dataset\n",
    "dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
    "data_dir = pathlib.Path(tf.keras.utils.get_file('flower_photos.tar', origin=dataset_url, extract=True)).with_suffix('')\n",
    "data_dir_s = str(data_dir)\n",
    "emissions_start = cc_tracker.flush()\n",
    "print('download, emissions start '+str(emissions_start))\n",
    "shutil.rmtree(data_dir_s, ignore_errors=True)\n",
    "data_dir = pathlib.Path(tf.keras.utils.get_file('flower_photos.tar', origin=dataset_url, extract=True)).with_suffix('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1eed555-5169-4ad8-8d2f-259777fb8e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create folder for unused data\n",
    "print('directories setup')\n",
    "path_elements = data_dir_s.split(os.sep)\n",
    "path_elements[-1] = '~'+path_elements[-1]\n",
    "unused_dir_s = os.sep.join(path_elements)\n",
    "shutil.rmtree(unused_dir_s, ignore_errors=True)\n",
    "os.makedirs(unused_dir_s, exist_ok=True)\n",
    "subfolders = [ f.name for f in os.scandir(data_dir_s) if f.is_dir() ]\n",
    "for subfolder in subfolders:\n",
    "    subfolder_path_elements = path_elements + [ subfolder ]\n",
    "    subfolder_path = os.sep.join(subfolder_path_elements)\n",
    "    os.makedirs(subfolder_path, exist_ok=True)\n",
    "emissions_stop = cc_tracker.flush()\n",
    "print('download, emissions stop '+str(emissions_stop))\n",
    "if emissions_start is not None and emissions_stop is not None:\n",
    "    report['download']['energy']['codecarbon'] = emissions_stop-emissions_start\n",
    "else:\n",
    "    print('CodeCarbon flushes during download failed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a5e2b6-eeba-4484-b97a-319f4798962c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# images centered-square cropping\n",
    "print('crop dataset')\n",
    "for subfolder in subfolders:\n",
    "    subfolder_content = list(os.scandir(os.sep.join([ data_dir_s, subfolder ])))\n",
    "    for f in subfolder_content:\n",
    "        img = Image.open(f.path)\n",
    "        # keep image vertical despite possible undue transformation at loading time\n",
    "        if img.size[0] > img.size[1]:\n",
    "            img = img.transpose(Image.Transpose.ROTATE_270)\n",
    "        half_square_side = int(min(img.size[0], img.size[1])/2)-1\n",
    "        img = img.crop((int(img.size[0]/2)-half_square_side, int(img.size[1]/2)-half_square_side, int(img.size[0]/2)+half_square_side, int(img.size[1]/2)+half_square_side))\n",
    "        img.save(fp=f.path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3fa6dd-0e76-4d7c-a57a-3bbadcb3e0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# frozen random numbers\n",
    "print('load permanent random filenames')\n",
    "initial_renames = load(filename=os.sep.join([ '.', '.'.join([ 'initial_renames', JOBLIB_FILE_EXTENSION ])]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbd975c-e203-4eb5-9ea2-462558584ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename original files\n",
    "index = 0\n",
    "for subfolder in subfolders:\n",
    "    data_dir_subfolder = os.sep.join([ data_dir_s, subfolder ])\n",
    "    for f in list(os.scandir(data_dir_subfolder)):\n",
    "        shutil.move(f.path, os.sep.join([ data_dir_subfolder, '.'.join([ initial_renames[index], 'jpg' ]) ]))\n",
    "        index += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa94938-5dd9-4ef7-b43b-4f0657b5a2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# frozen image transformations\n",
    "print('load permanent random transformations')\n",
    "transformations = load(filename=os.sep.join([ '.', '.'.join([ 'transformations', JOBLIB_FILE_EXTENSION ])]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07709f6-0c40-48ae-9bcc-f9f99a0c7de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra images generation to get balanced classes\n",
    "print('balance classes with extra images')\n",
    "index_bis = 0\n",
    "for subfolder in subfolders:\n",
    "    subfolder_index = 0\n",
    "    subfolder_content = list(os.scandir(os.sep.join([ data_dir_s, subfolder ])))\n",
    "    class_population = len(subfolder_content)\n",
    "    if class_population >= TARGET_POPULATION_PER_CLASS:\n",
    "        continue\n",
    "    for i in range(class_population, TARGET_POPULATION_PER_CLASS):\n",
    "        img = Image.open(subfolder_content[subfolder_index].path)    \n",
    "        # flip horizontally and vertically on a random basis\n",
    "        if transformations[index_bis]['flip_lr']:\n",
    "            img = img.transpose(Image.Transpose.FLIP_LEFT_RIGHT)\n",
    "        if transformations[index_bis]['flip_tb']:\n",
    "            img = img.transpose(Image.Transpose.FLIP_TOP_BOTTOM)\n",
    "        half_square_side = int(transformations[index_bis]['zoom_factor'] * min(img.size[0], img.size[1])/3)\n",
    "        img = img.rotate(angle=transformations[index_bis]['angle']*transformations[index_bis]['angle_sign'])\n",
    "        img = img.crop((int(img.size[0]/2)-half_square_side, int(img.size[1]/2)-half_square_side, int(img.size[0]/2)+half_square_side, int(img.size[1]/2)+half_square_side))\n",
    "        img.save(fp=os.sep.join([ unused_dir_s, subfolder, '.'.join([ initial_renames[index], 'jpg' ]) ]))\n",
    "        index += 1\n",
    "        index_bis +=1\n",
    "        subfolder_index += 1\n",
    "        if subfolder_index == len(subfolder_content):\n",
    "            subfolder_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb9a4a8-0d22-4cee-b6b7-54d0d616510c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# move per class a ratio of random files to reduce the number of items processed\n",
    "def split_files_per_class(percent_used:float=1.0):\n",
    "    for subfolder in subfolders:\n",
    "        # first, reset the directories\n",
    "        data_dir_subfolder = os.sep.join([ data_dir_s, subfolder ])\n",
    "        unused_dir_subfolder = os.sep.join([ unused_dir_s, subfolder ])\n",
    "        for f in os.scandir(unused_dir_subfolder):\n",
    "            shutil.move(f.path, os.sep.join([ data_dir_subfolder, f.name ]))\n",
    "            \n",
    "        # proceed with moving percentage\n",
    "        if percent_used > 0.999:\n",
    "            continue\n",
    "        class_image_count = len(list(data_dir.glob('{}{}*.jpg'.format(subfolder, os.sep))))\n",
    "        num_to_move = int(math.floor((1.0-percent_used)*class_image_count))\n",
    "        for i in range(0, num_to_move):\n",
    "            random_file=os.listdir(data_dir_subfolder)[0]\n",
    "            shutil.move(os.sep.join([ data_dir_subfolder, random_file ]),\n",
    "                        os.sep.join([ unused_dir_subfolder, random_file ]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3bece9-7cd3-459b-8e88-eaca6644dd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset after initial images generation\n",
    "print('move extra images to active space')\n",
    "split_files_per_class()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c86edff-deb6-4b7d-8107-ea2cf0175d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# images count and folder info\n",
    "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "print(str(image_count))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424d4158-5b47-44a8-b2c4-0c4c2b86aeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# naive baseline classifier\n",
    "def baseline(img_size:int, classes:int, activation:str='softmax') -> Model:\n",
    "  return Sequential([\n",
    "      Input((img_size, img_size, 3)),\n",
    "      layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "      layers.MaxPooling2D(),\n",
    "      layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "      layers.MaxPooling2D(),\n",
    "      layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "      layers.MaxPooling2D(),\n",
    "      layers.Dropout(0.2),\n",
    "      layers.Flatten(),\n",
    "      layers.Dense(128, activation='relu'),\n",
    "      layers.Dense(classes, activation=activation, name='outputs')\n",
    "  ])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3ca08c-b7bf-4dac-b8a0-d3780050d2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inception v3 model\n",
    "def inception_v3(img_size:int, classes:int, activation:str='softmax') -> Model:\n",
    "    model = tf.keras.applications.InceptionV3(\n",
    "        include_top=True,\n",
    "        input_tensor=None,\n",
    "        weights=None,\n",
    "        input_shape=(img_size, img_size, 3),\n",
    "        pooling=None,\n",
    "        classes=classes,\n",
    "        classifier_activation=activation,\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32488367-52d5-467b-a59e-fa1e907b41e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet50 identity block\n",
    "def identity_block(X: tf.Tensor, level: int, block: int, filters: List[int]) -> tf.Tensor:\n",
    "    # layers will be called conv{level}_iden{block}_{convlayer_number_within_block}'\n",
    "    conv_name = f'conv{level}_{block}' + '_{layer}_{type}'\n",
    "    # unpack number of filters to be used for each conv layer\n",
    "    f1, f2, f3 = filters\n",
    "    # the shortcut branch of the identity block\n",
    "    # takes the value of the block input\n",
    "    X_shortcut = X\n",
    "    # first convolutional layer (plus batch norm & relu activation, of course)\n",
    "    X = Conv2D(filters=f1, kernel_size=(1, 1), strides=(1, 1),\n",
    "               padding='valid', name=conv_name.format(layer=1, type='conv'),\n",
    "               kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=conv_name.format(layer=1, type='bn'))(X)\n",
    "    X = Activation('relu', name=conv_name.format(layer=1, type='relu'))(X)\n",
    "    # second convolutional layer\n",
    "    X = Conv2D(filters=f2, kernel_size=(3, 3), strides=(1, 1),\n",
    "               padding='same', name=conv_name.format(layer=2, type='conv'),\n",
    "               kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=conv_name.format(layer=2, type='bn'))(X)\n",
    "    X = Activation('relu')(X)\n",
    "    # third convolutional layer\n",
    "    X = Conv2D(filters=f3, kernel_size=(1, 1), strides=(1, 1),\n",
    "               padding='valid', name=conv_name.format(layer=3, type='conv'),\n",
    "               kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=conv_name.format(layer=3, type='bn'))(X)\n",
    "    # add shortcut branch to main path\n",
    "    X = Add()([X, X_shortcut])\n",
    "    # relu activation at the end of the block\n",
    "    X = Activation('relu', name=conv_name.format(layer=3, type='relu'))(X)\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a30789f-8ed4-4c7e-988c-414838d66c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet50 convolutional block\n",
    "def convolutional_block(X: tf.Tensor, level: int, block: int, filters: List[int], s: Tuple[int,int,int]=(2, 2)) -> tf.Tensor:\n",
    "     # layers will be called conv{level}_{block}_{convlayer_number_within_block}'\n",
    "    conv_name = f'conv{level}_{block}' + '_{layer}_{type}'\n",
    "    # unpack number of filters to be used for each conv layer\n",
    "    f1, f2, f3 = filters\n",
    "    # the shortcut branch of the convolutional block\n",
    "    X_shortcut = X\n",
    "    # first convolutional layer\n",
    "    X = Conv2D(filters=f1, kernel_size=(1, 1), strides=s, padding='valid',\n",
    "               name=conv_name.format(layer=1, type='conv'),\n",
    "               kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=conv_name.format(layer=1, type='bn'))(X)\n",
    "    X = Activation('relu', name=conv_name.format(layer=1, type='relu'))(X)\n",
    "    # second convolutional layer\n",
    "    X = Conv2D(filters=f2, kernel_size=(3, 3), strides=(1, 1), padding='same',\n",
    "               name=conv_name.format(layer=2, type='conv'),\n",
    "               kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=conv_name.format(layer=2, type='bn'))(X)\n",
    "    X = Activation('relu', name=conv_name.format(layer=2, type='relu'))(X)\n",
    "    # third convolutional layer\n",
    "    X = Conv2D(filters=f3, kernel_size=(1, 1), strides=(1, 1), padding='valid',\n",
    "               name=conv_name.format(layer=3, type='conv'),\n",
    "               kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=conv_name.format(layer=3, type='bn'))(X)\n",
    "    # shortcut path\n",
    "    X_shortcut = Conv2D(filters=f3, kernel_size=(1, 1), strides=s, padding='valid',\n",
    "                        name=conv_name.format(layer='short', type='conv'),\n",
    "                        kernel_initializer=glorot_uniform(seed=0))(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis=3, name=conv_name.format(layer='short', type='bn'))(X_shortcut)\n",
    "    # add shortcut branch to main path\n",
    "    X = Add()([X, X_shortcut])\n",
    "    # nonlinearity\n",
    "    X = Activation('relu', name=conv_name.format(layer=3, type='relu'))(X)\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e33319e-93fb-4eaa-a7e6-54d61dc9213b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet50 model\n",
    "def resnet_50(img_size:int, classes:int, activation:str='softmax') -> Model:\n",
    "    input_size = (img_size, img_size, 3)\n",
    "    # tensor placeholder for the model's input\n",
    "    X_input = Input(input_size)\n",
    "    ### Level 1 ###\n",
    "    # padding\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "    # convolutional layer, followed by batch normalization and relu activation\n",
    "    X = Conv2D(filters=64, kernel_size=(7, 7), strides=(2, 2),\n",
    "               name='conv1_1_1_conv',\n",
    "               kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name='conv1_1_1_nb')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    ### Level 2 ###\n",
    "    # max pooling layer to halve the size coming from the previous layer\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "    # 1x convolutional block\n",
    "    X = convolutional_block(X, level=2, block=1, filters=[64, 64, 256], s=(1, 1))\n",
    "    # 2x identity blocks\n",
    "    X = identity_block(X, level=2, block=2, filters=[64, 64, 256])\n",
    "    X = identity_block(X, level=2, block=3, filters=[64, 64, 256])\n",
    "    ### Level 3 ###\n",
    "    # 1x convolutional block\n",
    "    X = convolutional_block(X, level=3, block=1, filters=[128, 128, 512], s=(2, 2))\n",
    "    # 3x identity blocks\n",
    "    X = identity_block(X, level=3, block=2, filters=[128, 128, 512])\n",
    "    X = identity_block(X, level=3, block=3, filters=[128, 128, 512])\n",
    "    X = identity_block(X, level=3, block=4, filters=[128, 128, 512])\n",
    "    ### Level 4 ###\n",
    "    # 1x convolutional block\n",
    "    X = convolutional_block(X, level=4, block=1, filters=[256, 256, 1024], s=(2, 2))\n",
    "    # 5x identity blocks\n",
    "    X = identity_block(X, level=4, block=2, filters=[256, 256, 1024])\n",
    "    X = identity_block(X, level=4, block=3, filters=[256, 256, 1024])\n",
    "    X = identity_block(X, level=4, block=4, filters=[256, 256, 1024])\n",
    "    X = identity_block(X, level=4, block=5, filters=[256, 256, 1024])\n",
    "    X = identity_block(X, level=4, block=6, filters=[256, 256, 1024])\n",
    "    ### Level 5 ###\n",
    "    # 1x convolutional block\n",
    "    X = convolutional_block(X, level=5, block=1, filters=[512, 512, 2048], s=(2, 2))\n",
    "    # 2x identity blocks\n",
    "    X = identity_block(X, level=5, block=2, filters=[512, 512, 2048])\n",
    "    X = identity_block(X, level=5, block=3, filters=[512, 512, 2048])\n",
    "    # Pooling layers\n",
    "    X = AveragePooling2D(pool_size=(2, 2), name='avg_pool')(X)\n",
    "    # Output layer\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation=activation, name='fc_' + str(classes),\n",
    "              kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    # Create model\n",
    "    model = Model(inputs=X_input, outputs=X, name='ResNet50')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4ec608-da06-4140-87a4-c5f600fbd9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unitary model training and validation\n",
    "def play(cc_tracker:EmissionsTracker=None, model_name:str='baseline', batch_size:int=32, img_size:int=80, epochs:int=256, percent_used:float=1.0, activation:str='softmax', es:bool=True, optimizer:str='adam', learning_rate:float=0.001, report:dict=None):\n",
    "    session_id = str(uuid.uuid4())\n",
    "    if report is not None:\n",
    "        print('update report')\n",
    "        report['train'][session_id] = session_id\n",
    "        report['train']['context'] = {\n",
    "            'start_time': str(datetime.datetime.now())\n",
    "        }\n",
    "        report['train']['params'] = {\n",
    "            'algorithm': model_name,\n",
    "            'batch_size': batch_size,\n",
    "            'img_size': img_size,\n",
    "            'epochs': epochs, \n",
    "            'percent_used': percent_used,\n",
    "            'activation': activation,\n",
    "            'early_stopping': es,\n",
    "            'optimizer': optimizer,\n",
    "            'learning_rate': learning_rate\n",
    "        }\n",
    "\n",
    "    try:\n",
    "        print('flush CodeCarbon tracker')\n",
    "        emissions_start = cc_tracker.flush() if cc_tracker is not None else 1.0\n",
    "\n",
    "        # tailor dataset according to percent desired\n",
    "        print('split files')\n",
    "        split_files_per_class(percent_used)\n",
    "\n",
    "        # train\n",
    "        print('train dataset setup')\n",
    "        train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        data_dir,\n",
    "        validation_split=0.2,\n",
    "        subset='training',\n",
    "        seed=123,\n",
    "        image_size=(img_size, img_size),\n",
    "        batch_size=batch_size)\n",
    "\n",
    "        # validation\n",
    "        print('validation dataset setup')\n",
    "        val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        data_dir,\n",
    "        validation_split=0.2,\n",
    "        subset='validation',\n",
    "        seed=123,\n",
    "        image_size=(img_size, img_size),\n",
    "        batch_size=batch_size)\n",
    "        \n",
    "        # classes\n",
    "        class_names = train_ds.class_names\n",
    "        num_classes = len(class_names)\n",
    "        print('number of classes: '+str(num_classes))\n",
    "\n",
    "        # normalize\n",
    "        print('normalization')\n",
    "        normalization_layer = layers.experimental.preprocessing.Rescaling(1./255)\n",
    "        norm_train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "        norm_val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "        image_batch, labels_batch = next(iter(norm_train_ds))\n",
    "\n",
    "        # setup autotune\n",
    "        print('autotune')\n",
    "        AUTOTUNE = tf.data.AUTOTUNE\n",
    "        norm_train_ds = norm_train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "        norm_val_ds = norm_val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "        # model\n",
    "        print('model build')\n",
    "        if model_name not in CLASSIFIERS:\n",
    "            print('unknown model')\n",
    "            return None\n",
    "        model_func_call = '{}(img_size={}, classes={}, activation=\"{}\")'.format(model_name, str(img_size), str(num_classes), activation)\n",
    "        print('model function call is '+model_func_call)\n",
    "        op = None\n",
    "        if optimizer not in OPTIMIZERS:\n",
    "            print('unknown optimzer')\n",
    "            return None\n",
    "        beta_1 = max(0.5, 1.0-100*learning_rate)\n",
    "        beta_2 = max(0.95, 1.0-learning_rate)\n",
    "        if optimizer == 'adam':\n",
    "            op = tf.keras.optimizers.Adam(learning_rate=learning_rate, beta_1=beta_1, beta_2=beta_2)\n",
    "        elif optimizer == 'adamw':\n",
    "            op = tf.keras.optimizers.AdamW(learning_rate=learning_rate, beta_1=beta_1, beta_2=beta_2)\n",
    "        elif optimizer == 'nadam':\n",
    "            op = tf.keras.optimizers.Nadam(learning_rate=learning_rate, beta_1=beta_1, beta_2=beta_2)\n",
    "        model = eval(model_func_call)\n",
    "        model.compile(optimizer=op,\n",
    "                        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                        metrics=['accuracy'])\n",
    "        early = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=int(max(2, math.floor(epochs*0.1))), verbose=1, mode='auto')\n",
    "        o = model.fit(norm_train_ds, validation_data=norm_val_ds, epochs=epochs, callbacks=[early]) if es else model.fit(norm_train_ds, validation_data=norm_val_ds, epochs=epochs)\n",
    "        \n",
    "        # visualize new training results\n",
    "        acc = o.history['accuracy']\n",
    "        val_acc = o.history['val_accuracy']\n",
    "        loss = o.history['loss']\n",
    "        val_loss = o.history['val_loss']\n",
    "        stopped_epoch = epochs if early.stopped_epoch <= 0 else early.stopped_epoch\n",
    "\n",
    "    except Exception as err:\n",
    "        if report is not None:\n",
    "            report['train']['context']['exception'] = str(err)\n",
    "            report['train']['context']['end_time'] = str(datetime.datetime.now())\n",
    "        return None\n",
    "\n",
    "    # populate report if any\n",
    "    if report is not None:\n",
    "        report['train']['model'] = {\n",
    "            'acc': acc,\n",
    "            'val_acc': val_acc,\n",
    "            'loss': loss,\n",
    "            'val_loss': val_loss\n",
    "        }\n",
    "        if es:\n",
    "            report['train']['model']['stopped_epoch'] = stopped_epoch\n",
    "\n",
    "        print('session id {} with algorithm {}, flushing code carbon tracker'.format(session_id, model_name))\n",
    "        emissions_stop = cc_tracker.flush() if cc_tracker is not None else 0.0\n",
    "        report['train']['energy'] = {\n",
    "            'codecarbon': emissions_stop-emissions_start\n",
    "        }\n",
    "        report['train']['context']['end_time'] = str(datetime.datetime.now())\n",
    "        \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5e758a-1e30-4b4b-a8b1-d94a74d19c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main task\n",
    "print('starting play model {} size {} epochs {} percent {} activation {} early stopping {}'.format(algorithm, str(image_size), str(EPOCHS), str(percent), ACTIVATION, str(early_stopping)))\n",
    "try:\n",
    "\n",
    "    play(\n",
    "        cc_tracker=cc_tracker, \n",
    "        model_name=algorithm, \n",
    "        batch_size=batch_size, \n",
    "        img_size=image_size, \n",
    "        epochs=EPOCHS, \n",
    "        percent_used=percent, \n",
    "        activation=ACTIVATION, \n",
    "        es=early_stopping,\n",
    "        optimizer=optimizer,\n",
    "        learning_rate=learning_rate,\n",
    "        report=report)\n",
    "\n",
    "except Exception as err:\n",
    "    print('exception raised: '+str(err))\n",
    "\n",
    "print('ending play model')\n",
    "split_files_per_class() # reset directories' content\n",
    "cc_tracker.stop() \n",
    "\n",
    "with open(report_filepath, 'w', encoding='utf-8') as outfile:\n",
    "    json.dump(report, outfile, indent=4, ensure_ascii=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3380c5f1-20ca-40b9-9faf-8e913f8ed07f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
